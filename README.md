# Distributed Rate Limiter API

A production-ready, distributed rate limiting service built with FastAPI and Redis. Supports multiple rate limiting algorithms with atomic operations to prevent race conditions in distributed environments.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)
[![Redis](https://img.shields.io/badge/Redis-7.0+-red.svg)](https://redis.io/)
[![Docker](https://img.shields.io/badge/Docker-ready-blue.svg)](https://www.docker.com/)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Load Balancer                                  â”‚
â”‚                         (Nginx / AWS ALB / etc.)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚                 â”‚
                    â–¼                 â–¼                 â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   FastAPI        â”‚ â”‚   FastAPI        â”‚ â”‚   FastAPI        â”‚
         â”‚   Instance 1     â”‚ â”‚   Instance 2     â”‚ â”‚   Instance N     â”‚
         â”‚   :8000          â”‚ â”‚   :8000          â”‚ â”‚   :8000          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                    â”‚                    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚                 Redis                   â”‚
                  â”‚          (Distributed State)            â”‚
                  â”‚                                         â”‚
                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                  â”‚  â”‚Token Bucket â”‚  â”‚ Sliding Window  â”‚   â”‚
                  â”‚  â”‚   Keys      â”‚  â”‚     Keys        â”‚   â”‚
                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Decisions

1. **Atomic Lua Scripts**: All rate limiting operations use Redis Lua scripts to ensure atomicity, preventing race conditions even under high concurrency.

2. **Stateless API Servers**: The FastAPI instances are stateless, allowing horizontal scaling without session affinity.

3. **Redis as Single Source of Truth**: All rate limiting state is stored in Redis, enabling true distributed rate limiting.

---

## ğŸ“Š Rate Limiting Algorithms

### Token Bucket Algorithm

The Token Bucket algorithm is ideal for APIs that need to allow **burst traffic** while maintaining an average rate limit.

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           TOKEN BUCKET                â”‚
    â”‚                                       â”‚
    â”‚   Capacity: 100 tokens                â”‚
    â”‚   Refill Rate: 100 tokens/60 sec      â”‚
    â”‚                                       â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
    â”‚   â”‚ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™ â”‚     â”‚
    â”‚   â”‚ ğŸª™ ğŸª™ ğŸª™ ğŸª™ ğŸª™            â”‚     â”‚  â† Tokens (13 remaining)
    â”‚   â”‚                             â”‚     â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
    â”‚              â†‘                        â”‚
    â”‚   Tokens refill continuously          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼ Request arrives
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Has tokens?   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
              Yes  â”‚   No
                   â”‚    â””â”€â”€â†’ âŒ DENY (429)
                   â”‚
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Consume 1     â”‚
           â”‚ token         â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
              âœ… ALLOW
```

**How it works:**
1. Each user has a "bucket" with a maximum capacity (e.g., 100 tokens)
2. Tokens are added at a constant rate (e.g., 100 tokens per 60 seconds â‰ˆ 1.67 tokens/sec)
3. Each request consumes 1 token
4. If no tokens available, request is denied
5. Bucket never exceeds maximum capacity

**Redis Storage:**
```
Key: token_bucket:{identifier}
Value: {
  tokens: 85.5,           // Current tokens (float for precision)
  last_refill: 1704067200 // Unix timestamp of last refill calculation
}
```

**Best for:**
- APIs that need to handle burst traffic
- User-facing APIs with variable request patterns
- When you want to be more lenient with short bursts

---

### Sliding Window Log Algorithm

The Sliding Window Log provides **precise rate limiting** by tracking exact request timestamps.

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    SLIDING WINDOW (60 seconds)                â”‚
    â”‚                                                               â”‚
    â”‚  Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚
    â”‚                                                               â”‚
    â”‚        Window Start              Now                          â”‚
    â”‚            â”‚                      â”‚                           â”‚
    â”‚            â–¼                      â–¼                           â”‚
    â”‚  â”€ â”€ â”€ â”€ â”€[â”¬â”€â”¬â”€â”¬â”€â”€â”€â”¬â”€â”¬â”€â”¬â”€â”¬â”€â”€â”€â”¬â”€â”¬â”€â”¬]â”€ â”€ â”€ â”€ â”€ â”€                â”‚
    â”‚            â”‚ â”‚ â”‚   â”‚ â”‚ â”‚ â”‚   â”‚ â”‚ â”‚                            â”‚
    â”‚            â–² â–² â–²   â–² â–² â–² â–²   â–² â–² â–²                            â”‚
    â”‚            â””â”€â”´â”€â”´â”€â”€â”€â”´â”€â”´â”€â”´â”€â”´â”€â”€â”€â”´â”€â”´â”€â”˜                            â”‚
    â”‚            Request timestamps (10 requests in window)         â”‚
    â”‚                                                               â”‚
    â”‚  Expired â”€â”€â–ºâ”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€ Active Window â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚               â”‚
    â”‚  (removed)                                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How it works:**
1. Store timestamp of every request in a sorted set
2. On each request, remove timestamps older than the window
3. Count remaining timestamps
4. If count < limit, allow request and add current timestamp
5. Otherwise, deny the request

**Redis Storage:**
```
Key: sliding_window:{identifier}
Value: Sorted Set [
  (score: 1704067200001, member: "1704067200001:abc123"),
  (score: 1704067200500, member: "1704067200500:def456"),
  ...
]
```

**Best for:**
- Strict rate limiting requirements
- When you need precise control over request distribution
- APIs where burst traffic is not acceptable

---

## ğŸš€ Quick Start

### Using Docker Compose (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/rate-limiter.git
cd rate-limiter

# Start the services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f api
```

The API will be available at:
- **API**: http://localhost:8000
- **Swagger Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Local Development

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: .\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start Redis (using Docker)
docker run -d --name redis -p 6379:6379 redis:7-alpine

# Run the API
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

---

## ğŸ“¡ API Usage

### Check Rate Limit

Check if a request should be allowed and consume one unit from the rate limit.

```bash
curl -X POST "http://localhost:8000/rate-limit/check" \
  -H "Content-Type: application/json" \
  -d '{
    "identifier": "user_123",
    "algorithm": "token_bucket",
    "limit": 100,
    "window_seconds": 60
  }'
```

**Response (Allowed):**
```json
{
  "allowed": true,
  "remaining": 99,
  "reset_in_seconds": 59.5,
  "retry_after": null
}
```

**Response (Denied):**
```json
{
  "allowed": false,
  "remaining": 0,
  "reset_in_seconds": 45.2,
  "retry_after": 12.5
}
```

### Get Status (Without Consuming)

Check current rate limit status without using any quota.

```bash
curl "http://localhost:8000/rate-limit/status/user_123?algorithm=token_bucket&limit=100&window_seconds=60"
```

**Response:**
```json
{
  "identifier": "user_123",
  "requests_used": 55,
  "limit": 100,
  "window_seconds": 60,
  "algorithm": "token_bucket",
  "reset_in_seconds": 30.5
}
```

### Reset Rate Limit

Clear rate limit data for an identifier.

```bash
curl -X DELETE "http://localhost:8000/rate-limit/reset/user_123"
```

**Response:**
```json
{
  "message": "Rate limit reset for user_123"
}
```

### Health Check

```bash
curl "http://localhost:8000/health"
```

**Response:**
```json
{
  "status": "healthy",
  "redis_connected": true,
  "version": "1.0.0"
}
```

---

## ğŸ”§ Configuration

Configure the application using environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_HOST` | `localhost` | Redis server hostname |
| `REDIS_PORT` | `6379` | Redis server port |
| `REDIS_PASSWORD` | `""` | Redis password (if required) |
| `REDIS_DB` | `0` | Redis database number |
| `REDIS_SSL` | `false` | Use SSL for Redis connection |
| `REDIS_URL` | `""` | Full Redis URL (overrides other Redis settings) |
| `REDIS_MAX_CONNECTIONS` | `50` | Maximum connections in pool |
| `DEFAULT_LIMIT` | `100` | Default rate limit |
| `DEFAULT_WINDOW_SECONDS` | `60` | Default window in seconds |
| `LOG_LEVEL` | `INFO` | Logging level |
| `LOG_FORMAT` | `json` | Log format (json or text) |

### Example .env file

```env
REDIS_HOST=redis.example.com
REDIS_PORT=6379
REDIS_PASSWORD=your-secure-password
REDIS_SSL=true
DEFAULT_LIMIT=1000
DEFAULT_WINDOW_SECONDS=60
LOG_LEVEL=INFO
```

---

## ğŸ“ˆ Performance Benchmarks

Load testing performed using Locust with the following configuration:
- **Hardware**: 4 CPU cores, 8GB RAM (Docker containers)
- **Redis**: Single instance, no clustering
- **Test Duration**: 5 minutes sustained load

### Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LOAD TEST RESULTS                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Requests per Second:                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                         â”‚
â”‚                                                                              â”‚
â”‚  Token Bucket:    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  2,500 req/s     â”‚
â”‚  Sliding Window:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        1,800 req/s     â”‚
â”‚                                                                              â”‚
â”‚  Response Times (p95):                                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                        â”‚
â”‚                                                                              â”‚
â”‚  Token Bucket:    < 5ms   â–ˆâ–ˆâ–ˆâ–ˆ                                               â”‚
â”‚  Sliding Window:  < 8ms   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                             â”‚
â”‚                                                                              â”‚
â”‚  Error Rate:      0.00%                                                      â”‚
â”‚  Redis CPU Usage: ~15%                                                       â”‚
â”‚  API CPU Usage:   ~40% (per instance)                                        â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Running Your Own Benchmarks

```bash
# Install locust
pip install locust

# Start the services
docker-compose up -d

# Run load test (opens web UI at http://localhost:8089)
locust -f locustfile.py --host=http://localhost:8000

# Or run headless
locust -f locustfile.py --host=http://localhost:8000 \
  --headless --users 100 --spawn-rate 10 --run-time 5m
```

---

## ğŸ§ª Running Tests

```bash
# Install test dependencies
pip install -r requirements.txt

# Run all tests
pytest

# Run with coverage
pytest --cov=app --cov-report=html

# Run specific test file
pytest tests/test_token_bucket.py -v

# Run specific test
pytest tests/test_token_bucket.py::TestTokenBucketLimiter::test_first_request_allowed -v
```

---

## ğŸš¢ Deployment

### Railway

[![Deploy on Railway](https://railway.app/button.svg)](https://railway.app/new)

1. Click the button above or go to [Railway](https://railway.app)
2. Create a new project from GitHub
3. Add a Redis service
4. Set environment variables:
   - `REDIS_URL`: (auto-configured by Railway)
   - `LOG_LEVEL`: `INFO`
5. Deploy!

### Render

1. Create a new Web Service
2. Connect your GitHub repository
3. Add a Redis service
4. Configure environment variables:
   ```
   REDIS_URL=$REDIS_URL
   LOG_LEVEL=INFO
   ```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rate-limiter
spec:
  replicas: 3
  selector:
    matchLabels:
      app: rate-limiter
  template:
    metadata:
      labels:
        app: rate-limiter
    spec:
      containers:
      - name: api
        image: your-registry/rate-limiter:latest
        ports:
        - containerPort: 8000
        env:
        - name: REDIS_HOST
          value: redis-service
        - name: REDIS_PORT
          value: "6379"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 10
```

---

## ğŸ”’ Production Recommendations

1. **Redis High Availability**: Use Redis Sentinel or Redis Cluster for production
2. **TLS**: Enable Redis SSL (`REDIS_SSL=true`) for encrypted connections
3. **Authentication**: Add API authentication (API keys, JWT, etc.)
4. **Monitoring**: Add Prometheus metrics endpoint
5. **Rate Limit Headers**: Add `X-RateLimit-*` headers to your proxy
6. **Circuit Breaker**: Implement fallback when Redis is unavailable

### Security Headers Example (Nginx)

```nginx
location /api/ {
    proxy_pass http://rate-limiter:8000/;
    
    # Add rate limit headers from response
    add_header X-RateLimit-Limit $upstream_http_x_ratelimit_limit;
    add_header X-RateLimit-Remaining $upstream_http_x_ratelimit_remaining;
    add_header X-RateLimit-Reset $upstream_http_x_ratelimit_reset;
}
```

---

## ğŸ“ Project Structure

```
rate-limiter/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application & endpoints
â”‚   â”œâ”€â”€ models.py            # Pydantic request/response models
â”‚   â”œâ”€â”€ config.py            # Settings & environment configuration
â”‚   â”œâ”€â”€ redis_client.py      # Redis connection management
â”‚   â””â”€â”€ algorithms/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ token_bucket.py  # Token Bucket implementation
â”‚       â””â”€â”€ sliding_window.py # Sliding Window Log implementation
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py          # Pytest fixtures
â”‚   â”œâ”€â”€ test_api.py          # API integration tests
â”‚   â”œâ”€â”€ test_token_bucket.py # Token Bucket unit tests
â”‚   â””â”€â”€ test_sliding_window.py # Sliding Window unit tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ locustfile.py            # Load testing configuration
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“§ Support

- Create an issue for bug reports or feature requests
- Star the repo if you find it useful! â­
